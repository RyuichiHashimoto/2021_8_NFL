{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880dcede",
   "metadata": {},
   "source": [
    "## reference\n",
    "https://www.kaggle.com/robikscube/helper-code-helmet-mapping-deepsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b42e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"xoxb-1743094101558-1743160852854-cMMECMu5S8R1qmuDIJ3j56U5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04d698",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd57ce6",
   "metadata": {},
   "source": [
    "### private library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487fdea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from external_lib.NFLlib.score import NFLAssignmentScorer, check_submission\n",
    "from external_lib.NFLlib.features import add_track_features\n",
    "\n",
    "from lib.math.coodinate import generate_rotation_maxrix\n",
    "from lib.math.coodinate import convert_3d_to_2d\n",
    "\n",
    "from lib.noglobal import noglobal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38695f48",
   "metadata": {},
   "source": [
    "### public library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25b7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e464364",
   "metadata": {},
   "source": [
    "## paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8ce498",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_debug_samples = 120\n",
    "random_state = 42\n",
    "CONF_THRE = 0.3\n",
    "max_iter = 1000\n",
    "DIG_STEP = 3\n",
    "DIG_MAX = 42\n",
    "base_dir = \"/work/data/input/nfl-health-and-safety-helmet-assignment\"\n",
    "\n",
    "debug = True\n",
    "\n",
    "\n",
    "paramater = {};\n",
    "paramater[\"n_debug_samples\"] = n_debug_samples\n",
    "paramater[\"random_state\"] = random_state\n",
    "paramater[\"CONF_THRE\"] = CONF_THRE\n",
    "paramater[\"max_iter\"] = max_iter\n",
    "paramater[\"DIG_STEP\"] = DIG_STEP\n",
    "paramater[\"DIG_MAX\"] = random_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4b4a7",
   "metadata": {},
   "source": [
    "## file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb1db1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(f\"{base_dir}/train_labels.csv\")\n",
    "\n",
    "if debug:\n",
    "    tracking = pd.read_csv(f'{base_dir}/train_player_tracking.csv')\n",
    "    helmets = pd.read_csv(f'{base_dir}/train_baseline_helmets.csv')\n",
    "else:\n",
    "    tracking = pd.read_csv(f'{base_dir}/test_player_tracking.csv')\n",
    "    helmets = pd.read_csv(f'{base_dir}/test_baseline_helmets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda52d5",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6dbcb5",
   "metadata": {},
   "source": [
    "### function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cdd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cols(df):\n",
    "    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n",
    "    if 'video' not in df.columns:\n",
    "        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c6f26",
   "metadata": {},
   "source": [
    "### both train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1a30a",
   "metadata": {},
   "source": [
    "### function difinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b9937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = add_track_features(tracking)\n",
    "tracking[\"z\"] = 6.0\n",
    "\n",
    "if debug:\n",
    "    helmets = add_cols(helmets)\n",
    "    labels = add_cols(labels)    \n",
    "    \n",
    "    # Select `n_debug_samples` worth of videos to debug with\n",
    "    sample_videos = labels['video'].drop_duplicates() \\\n",
    "        .sample(n_debug_samples, random_state=random_state).tolist()\n",
    "    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n",
    "    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n",
    "    helmets = helmets[helmets['video'].isin(sample_videos)]\n",
    "    labels = labels[labels['video'].isin(sample_videos)]\n",
    "\n",
    "    \n",
    "helmets[\"frame\"] = helmets[\"video_frame\"].apply(lambda x:x.split(\"_\")[3])\n",
    "helmets[\"video_frame_without_position\"] = helmets[\"video_frame\"].apply(lambda x: \"_\".join( x.split(\"_\")[:2] + [x.split(\"_\")[3]]   )  )\n",
    "    \n",
    "\n",
    "\n",
    "for key,hel_each_df in helmets.groupby(\"game_play\"):    \n",
    "    min_frame = hel_each_df[\"frame\"].astype(int).min()\n",
    "    max_frame = hel_each_df[\"frame\"].astype(int).max()\n",
    "    tracking = tracking[tracking[\"est_frame\"] > (min_frame-5)]\n",
    "    tracking = tracking[tracking[\"est_frame\"] < max_frame+5]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05a152",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae46f5a",
   "metadata": {},
   "source": [
    "### first part (basic allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6b49e",
   "metadata": {},
   "source": [
    "#### function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112a0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def find_nearest(array, value):\n",
    "    value = int(value)\n",
    "    array = np.asarray(array).astype(int)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "\n",
    "### [0,1]ではないけど、正規化\n",
    "@noglobal()\n",
    "def norm_arr(a):\n",
    "    a = a-a.min();\n",
    "    a = a/(a.max());\n",
    "    return a\n",
    "    \n",
    "@noglobal()\n",
    "def dist(a1,a2):\n",
    "    return np.linalg.norm(a1-a2);\n",
    "\n",
    "\n",
    "@noglobal()\n",
    "def dist_for_different_len(a1,a2,max_iter):\n",
    "    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n",
    "    \n",
    "    len_diff = len(a1) - len(a2);\n",
    "\n",
    "    a2 = norm_arr(a2);\n",
    "    \n",
    "    if len_diff == 0:\n",
    "        a1 = norm_arr(a1);\n",
    "        return dist(a1,a2),();\n",
    "    else:\n",
    "        min_dist = 10000;\n",
    "        min_delete_idx = None;\n",
    "        cnt = 0;\n",
    "        \n",
    "        del_list = list(itertools.combinations(range(len(a1)),len_diff));    \n",
    "        \n",
    "        ## 組み合わせの総数が指定した数より大きい場合、ランダムサンプリングする。。\n",
    "        if (len(del_list) > max_iter):\n",
    "            del_list = random.sample(del_list,max_iter);\n",
    "            \n",
    "        for delete_idx in del_list:\n",
    "            this_a1 = np.delete(a1,delete_idx);\n",
    "            this_a1 = norm_arr(this_a1);\n",
    "            this_dist = dist(this_a1,a2);\n",
    "            \n",
    "            if (min_dist > this_dist):\n",
    "                min_dist = this_dist\n",
    "                min_delete_idx = delete_idx;\n",
    "            \n",
    "            \n",
    "        return min_dist,min_delete_idx\n",
    "\n",
    "\n",
    "@noglobal()\n",
    "def rotate_arr(u,view, t, isDeg=True):\n",
    "    if isDeg:\n",
    "        t = np.deg2rad(t);\n",
    "        \n",
    "    if(view == \"Endzone\"):\n",
    "        from_base_point = np.array([150,0,6])\n",
    "        target_axis = \"y\"\n",
    "        to_Point = np.array([60,0,5])    \n",
    "        length_vector = from_base_point - to_Point                            \n",
    "        rotation_matrix = generate_rotation_maxrix(-1*t,axis=target_axis,isDeg=False);\n",
    "        from_point = to_Point + rotation_matrix@length_vector\n",
    "        \n",
    "        \n",
    "    elif(view == \"Sideline\"):\n",
    "        to_Point = np.array([60,53.3/2,0])\n",
    "        from_point = [60 + t,71,40]        \n",
    "    else:\n",
    "        raise Exception(f\"You can specify only Endzone or Sideline, not {view}\");\n",
    "    \n",
    "    \n",
    "    \n",
    "    return convert_3d_to_2d(u[[\"x\",\"y\",\"z\"]],from_point=from_point,to_point=to_Point)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "@noglobal(excepts = [\"rotate_arr\"])\n",
    "def dist_rot(tracking_df, a2,view,DIG_MAX,DIG_STEP,max_iter):\n",
    "    tracking_df = tracking_df.sort_values('x')\n",
    "    x = tracking_df['x']\n",
    "    y = tracking_df['y']\n",
    "    min_dist = 10000\n",
    "    min_idx = None\n",
    "    min_x = None\n",
    "    \n",
    "    best_angle = 0;\n",
    "    \n",
    "    \n",
    "    for dig in range(-1*DIG_MAX,DIG_MAX+1,DIG_STEP):                \n",
    "        \n",
    "        if (view == \"Endzone\"):        \n",
    "            if (dig <0):\n",
    "                arr = rotate_arr(tracking_df,view,180 + dig);\n",
    "            else:\n",
    "                arr = rotate_arr(tracking_df,view,dig);\n",
    "                \n",
    "            arr = arr[[\"vertical\",\"horizon\"]].values.T\n",
    "        elif (view == \"Sideline\"):\n",
    "            arr = rotate_arr(tracking_df,view,dig);\n",
    "            arr_df = arr\n",
    "            arr = arr[[\"horizon\",\"depth\"]].values.T\n",
    "        else:\n",
    "            raise Exception(f\"unknown view mode is specified: {view}\")\n",
    "                                                               \n",
    "        ##  a2: ヘルメットの座標        \n",
    "        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2,max_iter)\n",
    "        if min_dist > this_dist:\n",
    "            min_dist = this_dist\n",
    "            min_idx = this_idx\n",
    "            min_x = arr[0]\n",
    "            best_angle = dig\n",
    "        \n",
    "                            \n",
    "    tracking_df['x_rot'] = min_x\n",
    "    player_arr = tracking_df.sort_values('x_rot')['player'].values\n",
    "    players = np.delete(player_arr,min_idx)\n",
    "    \n",
    "    \n",
    "    return min_dist, players,best_angle  \n",
    "    \n",
    "\n",
    "@noglobal()\n",
    "def mapping_df(args):\n",
    "    \n",
    "    ##########################\n",
    "    ### data difinition ### \n",
    "    video_frame, helmets_df = args[:2]\n",
    "    tracking = args[2]\n",
    "    parameter = args[3]    \n",
    "    CONF_THRE = parameter[\"CONF_THRE\"];\n",
    "    DIG_STEP = parameter[\"DIG_STEP\"];\n",
    "    DIG_MAX = parameter[\"DIG_MAX\"];\n",
    "    max_iter = parameter[\"max_iter\"];\n",
    "            \n",
    "    gameKey,playID,view,frame = video_frame.split('_')\n",
    "    \n",
    "    gameKey = int(gameKey)\n",
    "    playID = int(playID)\n",
    "    frame = int(frame)\n",
    "        \n",
    "    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n",
    "    est_frame = find_nearest(this_tracking.est_frame.values, frame)\n",
    "    this_tracking = this_tracking[this_tracking['est_frame']==est_frame].reset_index()\n",
    "    ########################## \n",
    "        \n",
    "    len_this_tracking = len(this_tracking)\n",
    "    \n",
    "    helmets_df['center_h_p'] = (helmets_df['left']+helmets_df['width']/2).astype(int)\n",
    "    helmets_df['center_h_m'] = (helmets_df['left']+helmets_df['width']/2).astype(int)*-1\n",
    "    helmets_df = helmets_df[helmets_df['conf']>CONF_THRE].copy()\n",
    "    \n",
    "    \n",
    "        \n",
    "    if len(helmets_df) > len_this_tracking:\n",
    "        helmets_df = helmets_df.tail(len_this_tracking)\n",
    "    \n",
    "    ## x軸でソート\n",
    "    helmets_df_p = helmets_df.sort_values('center_h_p').copy()\n",
    "    \n",
    "    ## 逆順でもソート\n",
    "    helmets_df_m = helmets_df.sort_values('center_h_m').copy()\n",
    "    \n",
    "    \n",
    "    if view == 'Endzone':        \n",
    "        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n",
    "        \n",
    "    helmet_center_a2_p = helmets_df_p['center_h_p'].values\n",
    "    helmet_center_a2_m = helmets_df_m['center_h_m'].values\n",
    "    \n",
    "\n",
    "    min_dist_p, min_detete_idx_p,best_angle_p = dist_rot(this_tracking,helmet_center_a2_p,view,DIG_MAX,DIG_STEP,max_iter)    \n",
    "    min_dist_m, min_detete_idx_m,best_angle_m = dist_rot(this_tracking,helmet_center_a2_m,view,DIG_MAX,DIG_STEP,max_iter)\n",
    "\n",
    "    \n",
    "    if min_dist_p < min_dist_m:\n",
    "        min_dist = min_dist_p\n",
    "        min_detete_idx = min_detete_idx_p\n",
    "        tgt_df = helmets_df_p\n",
    "        best_angle = best_angle_p\n",
    "    else:\n",
    "        min_dist = min_dist_m\n",
    "        min_detete_idx = min_detete_idx_m\n",
    "        tgt_df = helmets_df_m\n",
    "        best_angle = best_angle_m\n",
    "    \n",
    "    \n",
    "    tgt_df['label'] = min_detete_idx\n",
    "    tgt_df['best_angle'] = best_angle\n",
    "    return tgt_df[['video_frame','left','width','top','height','label',\"best_angle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8320ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_list = []\n",
    "df_list = list(helmets.groupby('video_frame'))\n",
    "df_list = [list(element) + [tracking,paramater] for element in df_list];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873b0c8",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f00b4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from lib.slack import send_massage\n",
    "\n",
    "from lib.multiprocess import exe_multiprocess_ret_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1f8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1922/52141 [21:40<8:55:41,  1.56it/s] <string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1925/52141 [21:42<10:04:19,  1.38it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1930/52141 [21:43<6:44:21,  2.07it/s] <string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1935/52141 [21:46<6:53:15,  2.02it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1936/52141 [21:47<7:41:44,  1.81it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1941/52141 [21:50<8:13:33,  1.70it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▎         | 1952/52141 [21:54<5:55:23,  2.35it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1956/52141 [21:55<5:27:55,  2.55it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1967/52141 [21:56<2:57:45,  4.70it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1969/52141 [21:56<2:50:17,  4.91it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1971/52141 [21:57<3:05:17,  4.51it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1972/52141 [21:57<3:02:44,  4.58it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1974/52141 [21:57<2:41:11,  5.19it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1978/52141 [21:58<3:00:09,  4.64it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1979/52141 [21:59<3:17:18,  4.24it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1980/52141 [22:00<7:54:16,  1.76it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1986/52141 [22:03<6:54:05,  2.02it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 1994/52141 [22:05<3:47:51,  3.67it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  4%|▍         | 2001/52141 [22:10<6:08:59,  2.26it/s]<string>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "100%|██████████| 52141/52141 [4:49:04<00:00,  3.01it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score 0.2660\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "submission_output_list = [];\n",
    "\n",
    "#with open(\"all_sideline_upgrade.csv\",\"a\") as fout: \n",
    "#    fout.write(\"key,video,frame,validation score, best angle\\n\");\n",
    "\n",
    "#    for key, each_df in tqdm(helmets.groupby(\"video_frame\")):\n",
    "        \n",
    "        \n",
    "#        counter = counter +1;\n",
    "#        if (counter % 100 == 0):\n",
    "#            total = len(helmets.groupby(\"video_frame\"))\n",
    "#            send_massage(token = token,massage = f\"{counter} / {total} finished\")\n",
    "            \n",
    "            \n",
    "\n",
    "#        arg_list = [key,each_df.reset_index(),tracking,paramater];\n",
    "#        sub = mapping_df(arg_list)    \n",
    "\n",
    "\n",
    "#        ext_labels = labels[labels[\"video_frame\"]==key];\n",
    "#        scorer = NFLAssignmentScorer(ext_labels)\n",
    "#        baseline_score = scorer.score(sub)\n",
    "        \n",
    "#        best_angle = sub[\"best_angle\"].unique()\n",
    "#        frame = key.split(\"_\")[3]    \n",
    "        \n",
    "#        video = \"_\".join(key.split(\"_\")[:2])\n",
    "\n",
    "#        fout.write(f\"{key},{video},{frame},{baseline_score:0.4f},{best_angle[0]}\\n\")\n",
    "#        fout.flush()\n",
    "        \n",
    "#        submission_output_list.append(sub)\n",
    "        \n",
    "arg_list = [[ key,each_df.reset_index(),tracking,paramater] for key,each_df in helmets.groupby(\"video_frame\")];\n",
    "submission_output_list = exe_multiprocess_ret_as_list(mapping_df,arg_list)        \n",
    "submission_df_v2 = pd.concat(submission_output_list)\n",
    "        \n",
    "        \n",
    "debug = True\n",
    "if debug:\n",
    "    scorer = NFLAssignmentScorer(labels)\n",
    "    baseline_score = scorer.score(submission_df_v2)\n",
    "    print(f\"validation score {baseline_score:0.4f}\")\n",
    "    \n",
    "    \n",
    "\n",
    "send_massage(token = token,massage = f\"finish {baseline_score:0.4f}\")\n",
    "\n",
    "submission_df_v2.to_csv('submission-baseline_upgrade.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441d155",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94871a",
   "metadata": {},
   "source": [
    "endline_sub = submission_df_v2[submission_df_v2[\"video_frame\"].str.contains(\"Endzone\")]\n",
    "endline_labels = labels[labels[\"video_frame\"].str.contains(\"Endzone\")]\n",
    "\n",
    "#endline_sub\n",
    "#endline_sub\n",
    "scorer = NFLAssignmentScorer(endline_labels)\n",
    "baseline_score = scorer.score(endline_sub)\n",
    "print(f\"validation score {baseline_score:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b68fe",
   "metadata": {},
   "source": [
    "endline_sub = submission_df_v2[submission_df_v2[\"video_frame\"].str.contains(\"Sideline\")]\n",
    "endline_labels = labels[labels[\"video_frame\"].str.contains(\"Sideline\")]\n",
    "\n",
    "#endline_sub\n",
    "#endline_sub\n",
    "scorer = NFLAssignmentScorer(endline_labels)\n",
    "baseline_score = scorer.score(endline_sub)\n",
    "print(f\"validation score {baseline_score:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b674f",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from lib.multiprocess import exe_multiprocess_ret_as_list\n",
    "\n",
    "submission_df_list = exe_multiprocess_ret_as_list(mapping_df,df_list);\n",
    "\n",
    "submission_df_v2 = pd.concat(submission_df_list)\n",
    "#submission_df.to_csv('submission-baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34856409",
   "metadata": {},
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    scorer = NFLAssignmentScorer(labels)\n",
    "    baseline_score = scorer.score(submission_df_v2)\n",
    "    print(f\"validation score {baseline_score:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5bd59",
   "metadata": {},
   "source": [
    "## 解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3eb5cd",
   "metadata": {},
   "source": [
    "sub_result = pd.read_csv(\"all_result_modifyed.csv\")\n",
    "sub_result[\"zone\"] = sub_result[\"key\"].apply(lambda x:x.split(\"_\")[2])\n",
    "\n",
    "\n",
    "sub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce7663",
   "metadata": {},
   "source": [
    "sub_result[sub_result[\"zone\"]==\"Sideline\"].sort_values([\"video\",\"zone\",\"frame\"]).groupby([\"video\",\"zone\"]).mean()[\"validation score\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf56698",
   "metadata": {},
   "source": [
    "## 旧バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476ec4c",
   "metadata": {},
   "source": [
    "## Deep Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from external_lib.deep_sort_pytorch.utils.parser import get_config\n",
    "from external_lib.deep_sort_pytorch.deep_sort import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38372279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_color_for_id(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the id\n",
    "    \"\"\"\n",
    "    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "\n",
    "def plot_one_box(x, im, color=None, label=None, line_thickness=3):\n",
    "    # Plots one bounding box on image 'im' using OpenCV\n",
    "    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n",
    "    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label: \n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deepsort_helmets(video_data,\n",
    "                     video_dir,\n",
    "                     deepsort_config='/work/config/deepsort.yaml',\n",
    "                     plot=False,\n",
    "                     plot_frames=[]):\n",
    "    \n",
    "    # Setup Deepsort\n",
    "    cfg = get_config()\n",
    "    cfg.merge_from_file(deepsort_config)    \n",
    "    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n",
    "                        max_dist=cfg.DEEPSORT.MAX_DIST,\n",
    "                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n",
    "                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n",
    "                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n",
    "                        max_age=cfg.DEEPSORT.MAX_AGE,\n",
    "                        n_init=cfg.DEEPSORT.N_INIT,\n",
    "                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n",
    "                        use_cuda=True)\n",
    "    \n",
    "    # Run through frames.\n",
    "    video_data = video_data.sort_values('frame').reset_index(drop=True)\n",
    "    ds = []\n",
    "    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n",
    "        d['x'] = (d['left'] + round(d['width'] / 2))\n",
    "        d['y'] = (d['top'] + round(d['height'] / 2))\n",
    "\n",
    "        xywhs = d[['x','y','width','height']].values\n",
    "\n",
    "        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n",
    "        \n",
    "        ##シーケンス\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        # 画像の色の順番を変更（BGR to RGB）\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        confs = np.ones([len(d),])\n",
    "        clss =  np.zeros([len(d),])\n",
    "        \n",
    "        outputs = deepsort.update(xywhs, confs, clss, image)\n",
    "\n",
    "        \n",
    "        #if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n",
    "        #    for j, (output, conf) in enumerate(zip(outputs, confs)): \n",
    "\n",
    "        #        bboxes = output[0:4]\n",
    "        #        id = output[4]\n",
    "        #        cls = output[5]\n",
    "\n",
    "        #        c = int(cls)  # integer class\n",
    "        #        label = f'{id}'\n",
    "        #        color = compute_color_for_id(id)\n",
    "        #        im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n",
    "        #    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        #    video_frame = d['video_frame'].values[0]\n",
    "        #    ax.set_title(f'Deepsort labels: {video_frame}')\n",
    "        #    plt.imshow(im)\n",
    "        #    plt.show()\n",
    "\n",
    "        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n",
    "        if len(preds_df) > 0:\n",
    "            # TODO Fix this messy merge\n",
    "            d = pd.merge_asof(d.sort_values(['left','top']),\n",
    "                              preds_df[['left','top','deepsort_cluster']] \\\n",
    "                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n",
    "                              direction='nearest')\n",
    "        ds.append(d)\n",
    "    dout = pd.concat(ds)\n",
    "    return dout\n",
    "\n",
    "\n",
    "def add_deepsort_label_col(out):\n",
    "    # Find the top occuring label for each deepsort_cluster\n",
    "    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n",
    "        .sort_values(ascending=False).to_frame() \\\n",
    "        .rename(columns={'label':'label_count'}) \\\n",
    "        .reset_index() \\\n",
    "        .groupby(['deepsort_cluster']) \\\n",
    "        .first()['label'].to_dict()\n",
    "    # Find the # of times that label appears for the deepsort_cluster.\n",
    "    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n",
    "        .sort_values(ascending=False).to_frame() \\\n",
    "        .rename(columns={'label':'label_count'}) \\\n",
    "        .reset_index() \\\n",
    "        .groupby(['deepsort_cluster']) \\\n",
    "        .first()['label_count'].to_dict()\n",
    "    \n",
    "    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n",
    "    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def score_vs_deepsort(myvideo, out, labels):\n",
    "    # Score the base predictions compared to the deepsort postprocessed predictions.\n",
    "    myvideo_mp4 = myvideo + '.mp4'\n",
    "    labels_video = labels.query('video == @myvideo_mp4')\n",
    "    scorer = NFLAssignmentScorer(labels_video)\n",
    "    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n",
    "    base_video_score = scorer.score(out_deduped)\n",
    "    \n",
    "    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n",
    "    print(out_preds.shape)\n",
    "    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n",
    "    print(out_preds.shape)\n",
    "    deepsort_video_score = scorer.score(out_preds)\n",
    "    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9319fc7",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9446ca",
   "metadata": {},
   "source": [
    "submission_df_v2 = pd.read_csv(\"submission-baseline_upgrade.csv\")\n",
    "submission_df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add video and frame columns to submission.\n",
    "submission_df = submission_df_v2;\n",
    "\n",
    "submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n",
    "submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n",
    "\n",
    "labels = pd.read_csv(f\"{base_dir}/train_labels.csv\")\n",
    "\n",
    "if debug:\n",
    "    video_dir = f\"{base_dir}/train/\"\n",
    "else:\n",
    "    video_dir = f\"{base_dir}/test/\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Loop through test videos and apply. If in debug mode show the score change.\n",
    "outs = []\n",
    "for myvideo, video_data in tqdm(submission_df.groupby('video'), total=submission_df['video'].nunique()):\n",
    "    #print(myvideo)\n",
    "    #print(f'==== {myvideo} ====')\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        # Plot deepsort labels when in debug mode.\n",
    "        out = deepsort_helmets(video_data, video_dir, plot_frames=[10, 150, 250])\n",
    "    else:\n",
    "        out = deepsort_helmets(video_data, video_dir)        \n",
    "    out = add_deepsort_label_col(out)\n",
    "    outs.append(out)\n",
    "    if debug:        \n",
    "        score_vs_deepsort(myvideo, out, labels)\n",
    "        \n",
    "    \n",
    "submission_deepsort = pd.concat(outs).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1e850",
   "metadata": {},
   "source": [
    "if debug:\n",
    "    scorer = NFLAssignmentScorer(labels)\n",
    "    baseline_score = scorer.score(submission_deepsort)\n",
    "    print(f\"validation score {baseline_score:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
